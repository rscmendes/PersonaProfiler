{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides some data and result analysis. \n",
    "I had to remove some of the cell outputs due to containing sensitive information. \n",
    "\n",
    "I invite you to run the cells using your own exported conversations.\n",
    "\n",
    "First let's look at all conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 199 conversations\n"
     ]
    }
   ],
   "source": [
    "# This loader is based on the script by Jacob Peacock (txtatech) \n",
    "# https://github.com/txtatech/chatgpt-export-to-text/tree/main\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the data from the JSON file\n",
    "with open(\"chatGPT-data/conversations.json\", \"r\") as read_file:  # adapt path as needed\n",
    "    data = json.load(read_file)\n",
    "\n",
    "# Empty list to hold all conversations\n",
    "all_conversations = []\n",
    "\n",
    "# Loop through each conversation in the data\n",
    "for conversation in data:\n",
    "    conversation_text = []\n",
    "\n",
    "    for current_node, node_details in conversation['mapping'].items():\n",
    "        message = node_details.get('message')\n",
    "\n",
    "        if message:\n",
    "            author_role = message['author']['role']\n",
    "            if 'parts' in message['content']:\n",
    "                content_parts = message['content']['parts']\n",
    "\n",
    "                # Create conversation text\n",
    "                text_string = \"\"\n",
    "                for part in content_parts:\n",
    "                    # Handle different data types in 'parts'\n",
    "                    if isinstance(part, str):\n",
    "                        text_string += part\n",
    "                    elif isinstance(part, dict):\n",
    "                        # Adjust based on the actual key(s) in the dictionary\n",
    "                        # Replace 'text' if necessary\n",
    "                        text_string += part.get('text', '')\n",
    "                    else:\n",
    "                        # Fallback to string conversion\n",
    "                        text_string += str(part)\n",
    "\n",
    "                text_prefix = \"User: \" if author_role == 'user' else \"ChatGPT: \"\n",
    "                text_string = text_prefix + text_string\n",
    "\n",
    "                conversation_text.append(text_string)\n",
    "\n",
    "    # Add this conversation to the all_conversations\n",
    "    if conversation_text:\n",
    "        # last_updated = conversation['update_time']\n",
    "        # conversation_id = conversation['conversation_id']\n",
    "        all_conversations.append({\n",
    "            \"conversation_id\": conversation['conversation_id'],\n",
    "            \"last_updated\": conversation['update_time'],\n",
    "            \"content\": \"\\n\".join(conversation_text),\n",
    "        })\n",
    "\n",
    "print(f\"Successfully loaded {len(all_conversations)} conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_id': '67dec3b0-bd04-8013-945d-7a160016c990',\n",
       " 'last_updated': 1742652353.347716,\n",
       " 'content': \"ChatGPT: \\nUser: Tell great book series related to the lord of the rings, the wheel of time, eragon and so on. Essentially medieval time, with magic\\nChatGPT: You're into the epic, high fantasy genre with deep worldbuilding, magic systems, and medieval vibes. If you like *The Lord of the Rings*, *The Wheel of Time*, and *Eragon*, here are some great series that’ll hit the same notes:\\n\\n---\\n\\n### **1. *The Stormlight Archive* by Brandon Sanderson**  \\n- Epic worldbuilding, unique magic systems, massive battles, and a deep lore.\\n- Starts with *The Way of Kings*.\\n- Similar to *The Wheel of Time* (Sanderson actually finished it after Jordan passed).\\n\\n---\\n\\n### **2. *A Song of Ice and Fire* by George R.R. Martin**  \\n- Gritty, political, medieval fantasy. Dragons, magic, betrayals.\\n- Starts with *A Game of Thrones*.\\n- More grounded and darker than Tolkien but still massive in scope.\\n\\n---\\n\\n### **3. *The Kingkiller Chronicle* by Patrick Rothfuss**  \\n- Told from the POV of a legendary magician/bard.\\n- Lyrical writing, deep magic system, mysterious world.\\n- Starts with *The Name of the Wind*.\\n- Still waiting on book 3, but books 1 & 2 are amazing.\\n\\n---\\n\\n### **4. *The Inheritance Trilogy* by N.K. Jemisin**  \\n- Gods walking among humans, political intrigue, rebellion.\\n- Not classic medieval, but it blends high fantasy with unique mythology and magic.\\n\\n---\\n\\n### **5. *The Faithful and the Fallen* by John Gwynne**  \\n- Pure heroic fantasy—good vs evil, ancient prophecies, sword fights, demons.\\n- Starts with *Malice*.\\n- Feels like a blend of *Eragon* and *The Wheel of Time* with Norse vibes.\\n\\n---\\n\\n### **6. *The Licanius Trilogy* by James Islington**  \\n- Time travel, prophecy, magic schools, mysterious pasts.\\n- Starts with *The Shadow of What Was Lost*.\\n- Often compared to *Wheel of Time* and *Mistborn*.\\n\\n---\\n\\n### **7. *The Broken Empire Trilogy* by Mark Lawrence**  \\n- A darker, grittier take on fantasy—anti-hero lead.\\n- Starts with *Prince of Thorns*.\\n- More brutal and philosophical, but still magical and medieval.\\n\\n---\\n\\n### **8. *Mistborn Series* by Brandon Sanderson**  \\n- A unique magic system using metals, heists, rebellion, ancient lore.\\n- Starts with *The Final Empire*.\\n- Slightly more industrial than medieval, but still deep fantasy at its core.\\n\\n---\\n\\nWant something more obscure or closer to *Eragon* with dragons and young heroes? Or maybe lighter/whimsical fantasy too?\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conversations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want the conversations sorted ascending by last_updated\n",
    "all_conversations.sort(key=lambda x: x['last_updated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_id': 'c402a3fb-5dca-41e5-913e-0d53179e6569',\n",
       " 'last_updated': 1687983248.0,\n",
       " 'content': \"ChatGPT: \\nUser: Which kind of machine learning techniques are used for user profiling?\\nChatGPT: Several machine learning techniques can be employed for user profiling. The choice of technique depends on the specific requirements of the profiling task and the available data. Here are some commonly used machine learning techniques for user profiling:\\n\\n1. **Supervised Learning**: Supervised learning techniques can be used when labeled data is available, where the user profiles are pre-defined or manually annotated. Some popular supervised learning algorithms for user profiling include:\\n\\n   - Decision Trees: Decision trees can be used to create rules for classifying users based on their attributes.\\n   - Naive Bayes: Naive Bayes classifiers can model the probability distribution of user attributes given their profiles.\\n   - Support Vector Machines (SVM): SVMs can be trained to find a hyperplane that separates different user profiles.\\n   - Random Forests: Random Forests can be used to ensemble decision trees and capture complex relationships between user attributes.\\n\\n2. **Unsupervised Learning**: Unsupervised learning techniques are useful when the user profiles are not pre-defined, and the goal is to discover hidden patterns or groups within the data. Common unsupervised learning algorithms for user profiling include:\\n\\n   - Clustering: Algorithms such as K-means, hierarchical clustering, or DBSCAN can group users based on their similarity, using attributes like demographics or behavioral patterns.\\n   - Principal Component Analysis (PCA): PCA can be applied to reduce the dimensionality of user attribute data while preserving the most important information.\\n   - Latent Dirichlet Allocation (LDA): LDA is a topic modeling technique that can discover latent topics or interests from user-generated content, such as text data.\\n\\n3. **Deep Learning**: Deep learning techniques, particularly neural networks, can be applied for user profiling tasks that involve large amounts of complex data, such as images, text, or sequences. Some relevant deep learning models for user profiling include:\\n\\n   - Convolutional Neural Networks (CNN): CNNs can be used for image-based user profiling, extracting features from images to understand user characteristics.\\n   - Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM): RNNs and LSTMs are effective for sequence data, such as user behavior or textual data, to capture temporal dependencies.\\n   - Transformer Models: Transformer-based models like the GPT (Generative Pre-trained Transformer) can be employed for tasks involving text-based user profiling, such as sentiment analysis or personality prediction.\\n\\nIt's important to note that the choice of technique depends on the specific use case, available data, and desired outcomes. Sometimes, a combination of these techniques may be used to achieve better user profiling results.\\nUser: How can deep learning be used for profiling?\\nChatGPT: Deep learning can be employed for profiling by leveraging its ability to extract complex patterns and representations from large amounts of data. Here are several ways in which deep learning techniques can be applied to user profiling:\\n\\n1. **Image-based Profiling**: Deep learning models, particularly Convolutional Neural Networks (CNNs), can analyze user images to infer various attributes such as age, gender, ethnicity, or facial expressions. By training CNNs on large labeled datasets, they can learn to recognize visual features and patterns that are indicative of specific user characteristics.\\n\\n2. **Text-based Profiling**: Deep learning models can process textual data, such as user-generated content, to infer personality traits, sentiment, or other attributes. Recurrent Neural Networks (RNNs) and variants like Long Short-Term Memory (LSTM) networks can capture the sequential dependencies in text and generate representations that capture the semantic meaning of the text.\\n\\n3. **Behavioral Profiling**: Deep learning techniques can analyze user behavior data, such as clickstream data or interaction logs, to identify patterns and preferences. Recurrent neural networks or sequence models like LSTMs can capture temporal dependencies and learn representations that reflect user preferences, interests, or patterns of interaction.\\n\\n4. **Audio-based Profiling**: Deep learning models can process audio data, such as speech or user-generated audio content, to infer attributes like age, gender, emotion, or accent. Convolutional neural networks or recurrent neural networks can be applied to extract relevant features from audio spectrograms or waveforms.\\n\\n5. **Multimodal Profiling**: Deep learning enables the integration of multiple modalities, such as combining text, image, and audio data, to build comprehensive user profiles. Multimodal models leverage architectures like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to process and fuse information from different modalities and learn joint representations that capture diverse user characteristics.\\n\\n6. **Transfer Learning**: Deep learning models pre-trained on large-scale datasets can be fine-tuned or adapted to user profiling tasks. For instance, pre-trained language models like BERT or GPT can be fine-tuned on specific user-related text data to capture domain-specific information and improve profiling performance.\\n\\n7. **Generative Models**: Deep learning generative models, such as Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs), can be utilized for generating synthetic user profiles. These models can learn the underlying distribution of user profiles and generate new profiles that are similar to the training data, allowing for data augmentation or privacy-preserving applications.\\n\\nDeep learning's ability to automatically learn complex features and representations from raw data makes it a powerful approach for user profiling across various domains. However, it's important to consider data privacy and ethical concerns when applying deep learning techniques for profiling purposes.\\nUser: which type of profiles are typically considered profiling with supervised learning?\\nChatGPT: In the context of supervised learning for user profiling, various types of profiles can be considered depending on the specific application or domain. Here are some common types of profiles that can be created using supervised learning techniques:\\n\\n1. **Demographic Profiles**: Demographic profiles involve classifying users based on attributes such as age, gender, location, occupation, income, or education level. Supervised learning algorithms can be trained on labeled data, where demographic attributes are known, to predict or classify the demographic profiles of new users.\\n\\n2. **Psychographic Profiles**: Psychographic profiles aim to capture users' personality traits, values, attitudes, and interests. Supervised learning models can be trained using labeled data, such as psychological questionnaires or surveys, to predict or categorize users into different psychographic profiles.\\n\\n3. **Behavioral Profiles**: Behavioral profiles focus on users' patterns of behavior, activities, or preferences. This can include classifying users based on their browsing behavior, purchase history, app usage, social media interactions, or other behavioral data. Supervised learning algorithms can learn from labeled data to identify patterns and classify users into specific behavioral profiles.\\n\\n4. **Interest Profiles**: Interest profiles involve categorizing users based on their interests, hobbies, or preferences. This can include classifying users into categories such as sports enthusiasts, movie lovers, music fans, foodies, or travelers. Supervised learning models can be trained using labeled data, such as user preferences or explicit interest tags, to predict or classify users into different interest profiles.\\n\\n5. **Sentiment Profiles**: Sentiment profiles focus on capturing users' sentiments, emotions, or opinions. This can involve classifying users' text data, such as reviews, comments, or social media posts, into categories like positive, negative, or neutral sentiment. Supervised learning algorithms can be trained on labeled sentiment data to predict or classify users' sentiment profiles.\\n\\n6. **Purchase Profiles**: Purchase profiles involve categorizing users based on their purchasing behavior or buying preferences. This can include classifying users into segments such as frequent buyers, price-conscious shoppers, luxury buyers, or deal hunters. Supervised learning models can be trained on labeled purchase data to predict or classify users into specific purchase profiles.\\n\\nIt's important to note that the types of profiles considered for supervised learning can vary depending on the specific use case and available labeled data. The selection of attributes and the definition of profiles will depend on the profiling goals and the characteristics of the user data being analyzed.\\nUser: is it possible to generate profiles with privacy guarantees\\nChatGPT: Yes, it is possible to generate profiles with privacy guarantees to protect sensitive user information. Several techniques can be employed to ensure privacy while still enabling effective profiling. Here are a few approaches:\\n\\n1. **Differential Privacy**: Differential privacy is a framework that provides strong privacy guarantees by adding controlled noise to the data or query responses. It ensures that the presence or absence of an individual's data does not significantly impact the results or compromise their privacy. Differential privacy mechanisms can be applied during data collection, aggregation, or analysis stages to protect user information while still allowing for effective profiling.\\n\\n2. **Privacy-preserving Machine Learning**: Privacy-preserving machine learning techniques aim to perform computations or train models on encrypted or perturbed data without revealing the underlying sensitive information. Techniques such as secure multiparty computation, homomorphic encryption, or federated learning can be employed to enable profiling while preserving privacy.\\n\\n3. **Data Anonymization**: Data anonymization involves removing or obfuscating direct identifiers from the dataset to prevent re-identification of individuals. Techniques like generalization, suppression, or noise addition can be used to transform or mask data attributes, making it more challenging to identify specific individuals while preserving overall statistical properties.\\n\\n4. **Aggregation and Group Profiling**: Instead of profiling individuals, aggregate or group-level profiling can be performed to analyze patterns and trends without exposing individual-level details. This approach allows for extracting useful insights while minimizing the risk of privacy breaches. Aggregation techniques like k-anonymity or l-diversity can be employed to ensure privacy at the group level.\\n\\n5. **Privacy Policies and User Consent**: Implementing transparent privacy policies and obtaining explicit user consent are important steps to respect user privacy. Clearly communicating the purposes of profiling, the types of data collected, and how the data will be used can help users make informed decisions and maintain control over their information.\\n\\nIt's crucial to carefully design and implement privacy measures based on the specific requirements, data sensitivity, and legal/regulatory considerations. Additionally, it's advisable to involve domain experts and legal professionals to ensure compliance with privacy laws and ethical guidelines.\\nUser: How would one use differential privacy for profiling?\\nChatGPT: Differential privacy can be applied to protect user privacy while performing profiling tasks. The goal is to ensure that the presence or absence of an individual's data does not significantly impact the profiling results, thereby providing privacy guarantees. Here's how differential privacy can be used for profiling:\\n\\n1. **Data Collection**: During the data collection stage, noise can be intentionally added to the collected data to provide privacy protection. For example, when gathering demographic or behavioral data from users, random noise can be introduced to individual data points before aggregation. This noise obscures the specific values and helps protect the privacy of individuals.\\n\\n2. **Query Responses**: When responding to queries or generating profiling results, differential privacy can be employed to add controlled noise to the output. The noise ensures that the response is statistically indistinguishable, whether a specific individual's data is included or not. By limiting the impact of individual contributions, privacy is preserved.\\n\\n3. **Data Aggregation**: Aggregating user data is a common step in profiling. Differential privacy techniques can be applied during the aggregation process to protect privacy. Aggregation mechanisms, such as adding noise or applying statistical techniques like randomized response, can be used to prevent the identification of specific individuals while still allowing for accurate profiling at a group level.\\n\\n4. **Model Training**: Differential privacy can also be applied during model training to ensure that the trained models do not memorize or encode specific details about individual users. By injecting noise into the training process or applying privacy-preserving learning techniques, the resulting models provide privacy guarantees while still being effective for profiling tasks.\\n\\n5. **Privacy Budget**: Differential privacy often involves a privacy budget that quantifies the amount of privacy loss allowed in a specific analysis or profiling task. The privacy budget limits the total amount of noise that can be introduced or the number of queries that can be made without compromising privacy. Adhering to the privacy budget ensures that privacy guarantees are maintained.\\n\\nIt's important to note that the amount of noise introduced should be carefully calibrated to balance privacy and utility. Too much noise can lead to inaccurate or unusable profiling results, while too little noise may risk privacy breaches. The specific techniques and parameters used for differential privacy depend on the particular profiling task and the privacy requirements of the application.\\n\\nApplying differential privacy for profiling requires expertise in privacy-preserving techniques, statistical methods, and an understanding of the specific use case. Consulting privacy experts and adhering to legal and ethical guidelines is crucial when incorporating differential privacy into profiling workflows.\\nUser: Can you give me an example on how differential privacy could be used in a scenario where we would like to show video recommendations based on user preferences\\nChatGPT: Certainly! Let's consider a scenario where a video streaming platform wants to provide personalized video recommendations to its users while ensuring their privacy using differential privacy. Here's an example of how differential privacy could be applied in this context:\\n\\n1. **Data Collection**: The platform collects user preferences and viewing history to understand their video interests. To preserve privacy, the platform can add random noise to the collected data. For instance, when recording a user's watch history, the platform can perturb the timestamps or add noise to the identifiers associated with the videos watched.\\n\\n2. **Profile Generation**: The platform aims to generate user profiles that capture their video preferences without revealing sensitive information. Using the differentially private data, the platform can aggregate user preferences at a group level instead of individual-level details. For example, instead of tracking each user's specific preferences, the platform can identify common video categories or genres preferred by a group of users to create profiles.\\n\\n3. **Recommendation Algorithm**: The differential privacy techniques can also be incorporated into the recommendation algorithm. When generating personalized recommendations, the algorithm can introduce controlled noise or randomness to the recommendation process. This ensures that the recommendations are not overly influenced by individual preferences and prevents the disclosure of specific user information.\\n\\n4. **Privacy Budget and Thresholds**: The differential privacy mechanism typically includes a privacy budget that determines the level of privacy protection. The platform needs to set appropriate privacy budget and thresholds to balance privacy and recommendation quality. The privacy budget restricts the amount of noise that can be added or the number of queries that can be made while maintaining privacy guarantees.\\n\\n5. **Evaluation and Feedback**: It's important for the platform to regularly evaluate and measure the utility of the recommendations while considering privacy implications. User feedback and interaction data, aggregated in a privacy-preserving manner, can be used to assess the quality and effectiveness of the recommendations, allowing for continuous improvement of the recommendation system.\\n\\nBy incorporating differential privacy into the data collection, profile generation, recommendation algorithm, and evaluation processes, the platform can provide video recommendations that are personalized while respecting user privacy. Differential privacy ensures that the recommendations are not overly influenced by individual preferences and that sensitive information remains protected.\\n\\nIt's worth noting that the specific implementation details of differential privacy, such as the choice of noise addition techniques and parameter settings, should be carefully determined based on the platform's requirements, the sensitivity of the data, and privacy regulations. Consulting privacy experts and following best practices is essential to effectively deploy differential privacy in such scenarios.\\nUser: Can you summarize different stages of the data or machine learning model where privacy methods can be applied?\\nChatGPT: Certainly! Privacy methods can be applied at various stages of data collection and machine learning models to protect user privacy. Here's a summary of the different stages where privacy methods can be employed:\\n\\n1. **Data Collection**: Privacy methods can be applied during the collection of user data to ensure that personally identifiable information is protected. Techniques such as differential privacy or data anonymization can be employed to add noise, perturb data, or remove direct identifiers, respectively, to prevent re-identification of individuals.\\n\\n2. **Data Storage and Management**: Privacy measures can be implemented to secure the storage and management of user data. This involves techniques such as data encryption, access controls, secure data handling protocols, and secure storage infrastructure to safeguard user information from unauthorized access or breaches.\\n\\n3. **Data Preprocessing**: During data preprocessing, privacy methods can be used to further anonymize or transform the data to protect individual privacy. Techniques such as k-anonymity, l-diversity, or generalization can be applied to make it more challenging to identify specific individuals while preserving the utility of the data for analysis.\\n\\n4. **Model Training**: Privacy-preserving techniques can be incorporated during the training of machine learning models to prevent overfitting or the memorization of sensitive information. Methods such as differential privacy, federated learning, or secure multiparty computation can be used to train models on encrypted or perturbed data, ensuring that user information remains private during the training process.\\n\\n5. **Model Deployment and Inference**: Privacy methods can be employed during model deployment and inference to protect user privacy in real-time applications. Techniques like secure inference protocols, on-device processing, or differential privacy mechanisms can be used to perform computations or predictions while preserving privacy and preventing information leakage.\\n\\n6. **Aggregation and Reporting**: When aggregating or reporting results derived from user data, privacy methods can be applied to ensure that individual-level information is not disclosed. Aggregation techniques, statistical privacy mechanisms, or controlled noise addition can be used to protect sensitive information while still providing useful insights or summaries.\\n\\n7. **User Interfaces and Consent**: Privacy considerations should also be integrated into user interfaces and consent processes. Providing clear privacy policies, granular consent options, and user control over their data empowers individuals to make informed decisions and manage their privacy preferences.\\n\\nIt's important to note that the specific privacy methods employed at each stage depend on factors such as the nature of the data, the privacy requirements, legal regulations, and ethical considerations. Tailoring privacy methods to the specific context and consulting privacy experts or legal professionals is crucial to ensure effective privacy protection throughout the data lifecycle and machine learning processes.\\nUser: Can you summarize different stages of the data when profiling users, where privacy methods can be applied?\\nChatGPT: Certainly! Privacy methods can be applied at various stages of data profiling to protect user privacy. Here's a summary of the different stages where privacy methods can be employed:\\n\\n1. **Data Collection**: Privacy methods can be applied during the collection of user data to ensure that personally identifiable information is protected. Techniques such as differential privacy, data anonymization, or pseudonymization can be employed to add noise, obfuscate data, or remove direct identifiers, respectively, to prevent re-identification of individuals.\\n\\n2. **Data Storage and Management**: Privacy measures can be implemented to secure the storage and management of user data. This involves techniques such as data encryption, access controls, secure data handling protocols, and secure storage infrastructure to safeguard user information from unauthorized access or breaches.\\n\\n3. **Data Preprocessing**: During data preprocessing for profiling, privacy methods can be used to further anonymize or transform the data to protect individual privacy. Techniques such as aggregation, suppression, or generalization can be applied to make it more challenging to identify specific individuals while preserving the utility of the data for profiling tasks.\\n\\n4. **Feature Selection and Extraction**: Privacy methods can be applied during the feature selection and extraction stage to ensure that sensitive or identifying information is not included in the profiling process. Careful consideration should be given to the selection of features to avoid encoding or revealing sensitive attributes that can lead to privacy breaches.\\n\\n5. **Model Training**: Privacy-preserving techniques can be incorporated during the training of profiling models to prevent the memorization or encoding of specific details about individuals. Methods such as differential privacy, federated learning, or secure multiparty computation can be used to train models on encrypted or perturbed data, ensuring that user information remains private during the training process.\\n\\n6. **Model Deployment and Inference**: Privacy methods can be employed during model deployment and inference to protect user privacy in real-time profiling applications. Techniques like secure inference protocols, on-device processing, or differential privacy mechanisms can be used to perform computations or predictions while preserving privacy and preventing information leakage.\\n\\n7. **Aggregation and Reporting**: When aggregating or reporting profiling results derived from user data, privacy methods can be applied to ensure that individual-level information is not disclosed. Aggregation techniques, statistical privacy mechanisms, or controlled noise addition can be used to protect sensitive information while still providing useful insights or summaries.\\n\\n8. **User Interfaces and Consent**: Privacy considerations should also be integrated into user interfaces and consent processes for profiling. Providing clear privacy policies, granular consent options, and user control over their data empowers individuals to make informed decisions and manage their privacy preferences.\\n\\nIt's important to note that the specific privacy methods employed at each stage depend on factors such as the nature of the data, the profiling objectives, privacy requirements, legal regulations, and ethical considerations. Adapting privacy methods to the specific context, conducting privacy impact assessments, and consulting privacy experts or legal professionals are crucial to ensure effective privacy protection throughout the data profiling process.\\nUser: Can you summarize different stages of  user profiling, where privacy methods can be applied?\\nChatGPT: Certainly! Privacy methods can be applied at various stages of user profiling to protect user privacy. Here's a summary of the different stages where privacy methods can be employed:\\n\\n1. **Data Collection**: Privacy methods can be applied during the collection of user data to ensure that personally identifiable information is protected. Techniques such as differential privacy, data anonymization, or pseudonymization can be employed to add noise, obfuscate data, or remove direct identifiers, respectively, to prevent re-identification of individuals.\\n\\n2. **Data Storage and Management**: Privacy measures can be implemented to secure the storage and management of user data. This involves techniques such as data encryption, access controls, secure data handling protocols, and secure storage infrastructure to safeguard user information from unauthorized access or breaches.\\n\\n3. **Data Preprocessing**: During data preprocessing for user profiling, privacy methods can be used to further anonymize or transform the data to protect individual privacy. Techniques such as aggregation, suppression, or generalization can be applied to make it more challenging to identify specific individuals while preserving the utility of the data for profiling tasks.\\n\\n4. **Feature Selection and Extraction**: Privacy methods can be applied during the feature selection and extraction stage to ensure that sensitive or identifying information is not included in the profiling process. Careful consideration should be given to the selection of features to avoid encoding or revealing sensitive attributes that can lead to privacy breaches.\\n\\n5. **Model Training**: Privacy-preserving techniques can be incorporated during the training of profiling models to prevent the memorization or encoding of specific details about individuals. Methods such as differential privacy, federated learning, or secure multiparty computation can be used to train models on encrypted or perturbed data, ensuring that user information remains private during the training process.\\n\\n6. **Model Deployment and Inference**: Privacy methods can be employed during model deployment and inference to protect user privacy in real-time profiling applications. Techniques like secure inference protocols, on-device processing, or differential privacy mechanisms can be used to perform computations or predictions while preserving privacy and preventing information leakage.\\n\\n7. **Aggregation and Reporting**: When aggregating or reporting profiling results derived from user data, privacy methods can be applied to ensure that individual-level information is not disclosed. Aggregation techniques, statistical privacy mechanisms, or controlled noise addition can be used to protect sensitive information while still providing useful insights or summaries.\\n\\n8. **User Interfaces and Consent**: Privacy considerations should also be integrated into user interfaces and consent processes for profiling. Providing clear privacy policies, granular consent options, and user control over their data empowers individuals to make informed decisions and manage their privacy preferences.\\n\\nIt's important to note that the specific privacy methods employed at each stage depend on factors such as the nature of the data, the profiling objectives, privacy requirements, legal regulations, and ethical considerations. Adapting privacy methods to the specific context, conducting privacy impact assessments, and consulting privacy experts or legal professionals are crucial to ensure effective privacy protection throughout the user profiling process.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conversations[0]\n",
    "# change the index until you find a conversation with sensitive information, then\n",
    "# prompt the profile extractor with that index to check if the model is able to extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data spawns from 2023-06-28 22:14:08 to 2025-03-22 15:05:53.347716 for a total of 632 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_date = datetime.fromtimestamp(all_conversations[0]['last_updated'])\n",
    "end_date = datetime.fromtimestamp(all_conversations[-1]['last_updated'])\n",
    "print(f\"Data spawns from {start_date} to {end_date} for a total of {(end_date-start_date).days} days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the output summary\n",
    "\n",
    "We have the summaries from 2 models: GPT-4o-mini and GPT-4o. Let's start with the results from the smaller\n",
    "\n",
    "## Summary from GPT-4o-mini\n",
    "With GPT-4o-mini I ran twice with some changes in the prompt but I got the following interesting discrepancy:\n",
    "- First run: identified as male due to having Mendes as name (makes no sense)\n",
    "- Second run: Identified as Emily Turner from a chat where it is clearly \"role-playing\"\n",
    "The results below are for the second run, since it was it the final prompt version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded summary containing 51 information pieces.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "summary_path = Path(\"outputs/gpt-4o-mini/summary_198.json\").resolve()\n",
    "with open(summary_path, \"r\") as read_file:  # adapt path as needed\n",
    "    summary = json.load(read_file)\n",
    "\n",
    "num_summary_points = len(summary)\n",
    "print(f\"Successfully loaded summary containing {num_summary_points} information pieces.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the summary into a dataframe to facilitate handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data that is explicitly mention in the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df[\"is_inferred\"] == False, ['information', 'reasoning']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gpt-4o-mini extracts things that aren't actually personal data. For example \"sampling_rate\", \"sensitivity\", \"template_improvement\". The reasoning part of these information however, actually contains interesting remarks: for example, for \"sampling_rate\" it states \"indicating an interest in audio processing\". So, while the \"information\" value is a bit strange, the \"reasoning\" then clarifies the extracted attribute.\n",
    "\n",
    "On a more negative note, the model does miss some interesting facts. Particularly, I uploaded my CV which contains my name as \"Ricardo S. C. Mendes\", but this information was not extracted. In fact, in the reasoning for \"age: 30\" it states \"The user identified themselves as Emily Turner, which is typically a female name.\", but then it does not have an \"information\" with \"name\". But worse than that was that the conversation with this information (24f3d331-184d-4366-8a0d-5b5c389d8ff6) was actually not about me; I was asking the model to classify whether a prompt was synthetically generated or created by an user. However, the model completely failed to assess the context and assumed that it was me. Moreover, the model also stated that my income was 10k euros net, but is actually not true. In that conversation I was asking help in calculatting taxes with some benefits for a simple example, and again, the model completely missed the context. I hope the larger model (gpt-4o) performs better in this regard.\n",
    "\n",
    "Finally, since it states that the gender is female from the name, then this is clearly an inference, it should be in the \"non-inferred\" pieces of information. Let's look at those now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data that was inferred by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df[\"is_inferred\"], ['information', 'reasoning']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these information are actually not inferred, but just assumed that I have interest because I asked about it. For example: \"The user asked about anime that resembles RPGs, indicating an interest in both anime and role-playing games\". This is not inferring, just clearly stated. \n",
    "\n",
    "There are however, some minor inferences:\n",
    "- The user holds Portuguese citizenship and resides in Germany, indicating potential dual tax residency\n",
    "- The user asked for suggestions on what to do in Peniche and Mira, indicating an interest in local culture and activities.\n",
    "\n",
    "But nothing really strong inferred. \n",
    "Let's check the profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_path = Path(\"outputs/gpt-4o-mini/profile_o3-mini.json\").resolve()\n",
    "with open(profile_path, \"r\") as file:\n",
    "    profile = json.load(file)\n",
    "\n",
    "print(json.dumps(profile, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a pretty good profile, with the exception of the wrong points that were already discussed:\n",
    "- Name\n",
    "- Gender (resulted from wrong name)\n",
    "- Income\n",
    "- Some weird points such as \"LLama Guard (llamas) and whimsical scenarios\" -- I think the model didn't actually understood what Llama Guard was, and thinks it's the animal rather than an LLM, and joined it together with my experiments on creating weird images (like a portrait of family potatoes)\n",
    "\n",
    "Let's see if GPT-4o had better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary from GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded summary containing 224 information pieces.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "summary_path = Path(\"outputs/gpt-4o/summary_concatenated.json\").resolve()\n",
    "with open(summary_path, \"r\") as read_file:  # adapt path as needed\n",
    "    summary = json.load(read_file)\n",
    "\n",
    "num_summary_points = len(summary)\n",
    "print(f\"Successfully loaded summary containing {num_summary_points} information pieces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 4 times more informations pieces. This could be a result of the Tokens per limit error that made me restart the experiments with empty summary at different phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "print(df.loc[df[\"is_inferred\"] == False, ['information', 'reasoning']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4o extracted significantly more information, even in the non-inferred pieces, particularly:\n",
    "- Family and friendship relationships\n",
    "- Additional financial status such as a loan and information on stocks.\n",
    "\n",
    "Funilly enough, it got that my name is both Ricardo Mendes and Emily Turner, however this time, it also got that my gender was explicitly stated (gpt-4o-mini missed it), so that in the final profile it actually gets the right name (as we will see later).\n",
    "\n",
    "Let's check the inferred data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df[\"is_inferred\"], ['information', 'reasoning']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to gpt-4o-mini, most of these inferences are very straightforward on the form of \"The user asked about X, showing interest in [generalization of x]. For example:\n",
    "- \"interest: healthy lifestyle\" because \"The user asked for healthy breakfast suggestions and life habits to boost energy and productivity\"\n",
    "- The user is asking about chimichangas, indicating an interest in culinary topics.\n",
    "\n",
    "\n",
    "There are few that I would actually consider inferred pieces of information such as:\n",
    "- The user is asking about NetworkX, a Python library used for the creation, manipulation, and study of complex networks of nodes and edges, which is commonly used in programming and data analysis.\n",
    "- The user is asking about turning off TalkBack on an Android device, indicating they use Android.\n",
    "\n",
    "\n",
    "There is also some incorrect information:\n",
    "- Still assumed that my income is 10.000€ anually, which is very strange because this conversation clearly states \"for example, if I receive 10.000€ per year how do these tax benefits apply?\". \n",
    "- In a conversation I asked for a bithday message for Elisa Mendes (which is my niece) that would fit in a bitcoin transation. Since we share the same last name, the model wrongly assumed that it was my daughter.\n",
    "- \"The user is translating slides from German to English, indicating proficiency in German.\" --> if anything this shows a lack of proficiency in German.\n",
    "\n",
    "Let's check the profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_path = Path(\"outputs/gpt-4o/profile_o3-mini.json\").resolve()\n",
    "with open(profile_path, \"r\") as file:\n",
    "    profile = json.load(file)\n",
    "\n",
    "print(json.dumps(profile, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely better than the model from the gpt-4o-mini summary, with more information, such as family relationships, and known languages. But it definitely propagated some errors like: having a daugther, 10k as annual income, dual PhD (it should've aggregated it into a single), and dual occupation since it is the same.\n",
    "\n",
    "Finally, run webperson_finder.py to see if the model can find you online."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llminspector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
